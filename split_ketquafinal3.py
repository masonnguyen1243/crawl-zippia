import json
import os

def split_ketquafinal3_file():
    """
    T√°ch file ketquafinal-3.json th√†nh 2 file nh·ªè h∆°n:
    - ketquafinal-4.json: 33 companies ƒë·∫ßu ti√™n
    - ketquafinal-5.json: 33 companies c√≤n l·∫°i
    """
    
    INPUT_FILE = 'ketquafinal-3.json'
    COMPANIES_PER_FILE = 33
    OUTPUT_FILES = ['ketquafinal-4.json', 'ketquafinal-5.json']
    
    # ƒê·ªçc file input
    try:
        print(f"üîÑ ƒêang ƒë·ªçc file input: {INPUT_FILE}")
        with open(INPUT_FILE, 'r', encoding='utf-8') as f:
            companies_data = json.load(f)
        print(f"‚úÖ ƒê√£ ƒë·ªçc th√†nh c√¥ng {len(companies_data)} companies")
    except FileNotFoundError:
        print(f"‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y file '{INPUT_FILE}'")
        return
    except json.JSONDecodeError as e:
        print(f"‚ùå L·ªói: File '{INPUT_FILE}' kh√¥ng ƒë√∫ng ƒë·ªãnh d·∫°ng JSON: {e}")
        return
    
    total_companies = len(companies_data)
    if total_companies == 0:
        print("‚ö†Ô∏è  Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ t√°ch")
        return
    
    print(f"üìä T·ªïng s·ªë companies: {total_companies}")
    print(f"üîß S·∫Ω t√°ch th√†nh {len(OUTPUT_FILES)} files v·ªõi {COMPANIES_PER_FILE} companies/file")
    
    # T√°ch d·ªØ li·ªáu th√†nh c√°c chunks
    for i, output_file in enumerate(OUTPUT_FILES):
        start_index = i * COMPANIES_PER_FILE
        end_index = min((i + 1) * COMPANIES_PER_FILE, total_companies)
        
        # L·∫•y chunk d·ªØ li·ªáu
        chunk = companies_data[start_index:end_index]
        chunk_size = len(chunk)
        
        if chunk_size == 0:
            print(f"‚ö†Ô∏è  File {output_file}: Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ ghi")
            continue
        
        # L∆∞u chunk v√†o file
        try:
            print(f"üíæ ƒêang l∆∞u {output_file}: companies {start_index + 1}-{end_index} ({chunk_size} companies)")
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(chunk, f, ensure_ascii=False, indent=2)
            
            print(f"‚úÖ ƒê√£ l∆∞u th√†nh c√¥ng {output_file}")
            
            # Th·ªëng k√™ jobs trong chunk
            total_jobs = sum(len(company.get("jobs", [])) for company in chunk)
            print(f"   üìã T·ªïng s·ªë jobs: {total_jobs}")
            
        except Exception as e:
            print(f"‚ùå L·ªói khi l∆∞u file {output_file}: {e}")
            return
    
    print(f"\nüéâ Ho√†n th√†nh t√°ch file!")
    print(f"üìä Th·ªëng k√™ cu·ªëi:")
    
    # Hi·ªÉn th·ªã th·ªëng k√™ t·ªïng qu√°t
    for i, output_file in enumerate(OUTPUT_FILES):
        start_index = i * COMPANIES_PER_FILE
        end_index = min((i + 1) * COMPANIES_PER_FILE, total_companies)
        actual_size = end_index - start_index
        
        if actual_size > 0:
            chunk = companies_data[start_index:end_index]
            total_jobs = sum(len(company.get("jobs", [])) for company in chunk)
            print(f"   - {output_file}: {actual_size} companies, {total_jobs} jobs")
    
    # Ki·ªÉm tra t·ªïng
    total_processed = sum(min(COMPANIES_PER_FILE, max(0, total_companies - i * COMPANIES_PER_FILE)) 
                         for i in range(len(OUTPUT_FILES)))
    print(f"   - T·ªïng ƒë√£ x·ª≠ l√Ω: {total_processed}/{total_companies} companies")
    
    # Hi·ªÉn th·ªã m·ªôt v√†i t√™n company ƒë·∫ßu ti√™n c·ªßa m·ªói file ƒë·ªÉ ki·ªÉm tra
    print(f"\nüîç M·∫´u d·ªØ li·ªáu:")
    for i, output_file in enumerate(OUTPUT_FILES):
        start_index = i * COMPANIES_PER_FILE
        end_index = min((i + 1) * COMPANIES_PER_FILE, total_companies)
        
        if start_index < total_companies:
            chunk = companies_data[start_index:end_index]
            if chunk:
                sample_name = chunk[0].get("name", chunk[0].get("companyName", "Kh√¥ng c√≥ t√™n"))
                print(f"   - {output_file}: B·∫Øt ƒë·∫ßu v·ªõi '{sample_name}'")

def main():
    print("üöÄ B·∫Øt ƒë·∫ßu t√°ch file ketquafinal-3.json...")
    split_ketquafinal3_file()

if __name__ == "__main__":
    main()